{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Watermelons without juice and the search for UQ\"\n",
        "\n",
        "execute: \n",
        "  echo: false\n",
        "  warning: false\n",
        "\n",
        "fig-width: 10 \n",
        "fig-height: 10\n",
        "---"
      ],
      "id": "0d9cb326"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "from matplotlib.patches import Patch, Circle, PathPatch\n",
        "import mpl_toolkits.mplot3d.art3d as art3d\n",
        "import os \n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "rel_dir = '/home/kitadam/ENR_Sven/musings/data/jet-all-full.csv'\n",
        "jet_pdb_all = pd.read_csv(rel_dir)\n",
        "jet_pdb_all = jet_pdb_all.convert_dtypes()\n",
        "jet_pdb = jet_pdb_all[(jet_pdb_all['elongation'] != -1) & (jet_pdb_all['Zeff'] != -1)]\n",
        "jet_pdb['P_NBI(MW)'][jet_pdb['P_NBI(MW)'] < 0] = 0.0 \n",
        "jet_pdb['gasflowrateofmainspecies10^22(e/s)'][jet_pdb['gasflowrateofmainspecies10^22(e/s)'] < 0] = 0.0 \n",
        "jet_pdb.loc[:, 'divertorconfiguration'] = jet_pdb.loc[:, 'divertorconfiguration'].astype('category')\n",
        "jet_pdb.loc[:, 'divertorconfiguration'] = jet_pdb.loc[:, 'divertorconfiguration'].cat.codes\n",
        "jet_pdb['wall'] = [int(i) for i in (jet_pdb['shot'] < 80000).to_list()]\n",
        "global_cols = ['BetaN(MHD)', 'Zeff']\n",
        "info_cols = ['shot', 't1', 't2']\n",
        "ped_cols = ['nepedheight10^19(m^-3)', 'error_nepedheight10^19(m^-3)']\n",
        "mp_cols = ['Ip(MA)', 'B(T)', 'a(m)', 'q95','averagetriangularity', 'plasmavolume(m^3)','elongation','P_NBI(MW)', 'P_ICRH(MW)', 'P_TOT=PNBI+Pohm+PICRH-Pshi(MW)',   'gasflowrateofmainspecies10^22(e/s)', ]\n",
        "cat_cols = ['FLAG:Kicks', 'FLAG:RMP', 'FLAG:pellets', 'divertorconfiguration', 'Atomicnumberofseededimpurity']\n",
        "flags = ['FLAG:DEUTERIUM', 'FLAG:HYDROGEN', 'FLAG:H/Dmix', 'FLAG:HeJET-C', 'FLAG:Seeding', 'FLAG:Kicks', 'FLAG:RMP', 'FLAG:pellets', 'FLAG:HRTSdatavalidated', 'divertorconfiguration', 'Atomicnumberofseededimpurity',]\n",
        "os.environ['PLOTSTYLE'] = '/home/kitadam/ENR_Sven/basematplotlibstyle.mplstyle'\n",
        "if os.getenv('PLOTSTYLE') is not None: \n",
        "    plt.style.use(os.getenv('PLOTSTYLE'))\n",
        "RED = \"#dd3015\"\n",
        "GREEN = \"#489A8C\"\n",
        "DARK = \"#1C2C22\"\n",
        "GOLD = \"#F87D16\"\n",
        "WHITE = \"#FFFFFF\"\n",
        "BLUE = \"#2E6C96\"\n",
        "PURPLE = '#d7a7ef'\n",
        "LIGHTBLUE = \"#a7bfef\""
      ],
      "id": "24363708",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "jet_c = jet_pdb[jet_pdb['shot'] < 81000]\n",
        "jet_ilw = jet_pdb[jet_pdb['shot'] > 81000]\n",
        "lorenzo_inputs = ['Ip(MA)', 'averagetriangularity', 'P_NBI(MW)','Meff']\n",
        "inputs = ['Ip(MA)', 'B(T)', 'a(m)', 'P_NBI(MW)', 'P_ICRH(MW)', 'P_TOT=PNBI+Pohm+PICRH-Pshi(MW)', 'plasmavolume(m^3)', 'q95', 'gasflowrateofmainspecies10^22(e/s)', 'elongation', 'averagetriangularity', 'FLAG:Kicks', 'FLAG:RMP', 'FLAG:pellets', 'Atomicnumberofseededimpurity', 'divertorconfiguration', 'wall']\n",
        "\n",
        "targets = 'nepedheight10^19(m^-3)'"
      ],
      "id": "fef24aeb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With high dimensional data, when splitting the data into train-test subsets, it is very unlikely that the test set falls into the convex hull of the training set, thus by measuring performance on the test set, we are likely measuring performance of the extrapolation rather than interpolation capabilities of the model [@HighDimLearning] (described for dummies [here](https://lauraruis.github.io/2021/11/06/extra.html)). \n",
        "\n",
        "The dilema for me is if we are always extrapolating, then somehow the UQ for a model should be defined in terms of the distance from the convex hull. Therefore, I want to investigate the properties of error in prediction for various models w.r.t the distance from the quiered point to the convex hull of the training set.  \n",
        "\n",
        "## Subset in convex hull? \n",
        "\n",
        "First we need an algorithm to see if a point is within the convex hull of the training set. \n",
        "\n",
        "- Maths \n",
        "- Algorithm as a linear programming problem [Stackoverflow Implementation](https://stackoverflow.com/questions/16750618/whats-an-efficient-way-to-find-if-a-point-lies-in-the-convex-hull-of-a-point-cl)\n",
        "\n",
        "We can check this then for the JET Pedestal database for varying input dimensions and splits. \n",
        "\n",
        "- **NB** Is the convex hull defined by the point cloud of input variables as well as target variable? Yes probably. \n"
      ],
      "id": "43c9b939"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import random \n",
        "from scipy.optimize import linprog\n",
        "\n",
        "random.seed(42)\n",
        "shuffled_idxs = random.sample(jet_pdb.index.to_list(), k=len(jet_pdb))\n",
        "\n",
        "jet_train, jet_test = jet_pdb.loc[shuffled_idxs[:-200]], jet_pdb.loc[shuffled_idxs[-200:]]\n",
        "\n",
        "X_train, y_train = jet_train[inputs], jet_train[targets]\n",
        "X_test, y_test = jet_test[inputs], jet_test[targets]\n",
        "# X_all, y_all = jet_pdb[inputs], jet_pdb[targets]\n",
        "\n",
        "def in_hull(points, x): # \n",
        "  n_points = len(points)\n",
        "  n_dim = len(x)\n",
        "  c = np.zeros(n_points)\n",
        "  A = np.r_[points.T,np.ones((1,n_points))]\n",
        "  b = np.r_[x, np.ones(1)]\n",
        "  lp = linprog(c, A_eq=A, b_eq=b)\n",
        "  return lp.success\n",
        "\n",
        "\n",
        "plt.scatter(X_train[inputs[0]], X_train[inputs[1]])\n",
        "\n",
        "\n",
        "for i in range(len(X_test)): \n",
        "  if in_hull(X_train.values, X_test.values[i]): \n",
        "    plt.scatter(X_test.values[i, 0], X_test.values[i, 1], color=RED)\n",
        "  else: \n",
        "    plt.scatter(X_test.values[i, 0], X_test.values[i, 1], color=PURPLE)\n",
        "\n",
        "plt.show()"
      ],
      "id": "45dc5b09",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Distance to convex hull? \n",
        "\n",
        "This is probably tricky, as we would have to calculate the convex hull for a high dimensional space. \n",
        "\n",
        "Maybe we should instead quantify the distance of the point to the closest point __inside__ the convex hull? \n",
        "\n",
        "## Applications \n",
        "\n",
        "1. Could we make graphs of the error vs distance vs dimenisonality of input space for both the parameter space as well as latent space for DIVA?\n",
        "2. How does error vs distance to hull vary as a function of model? And input space? "
      ],
      "id": "c37a0556"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}