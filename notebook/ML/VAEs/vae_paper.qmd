---
title: "An overview of VAEs and their applications to fusion"
author: "Adam Kit"
format: beamer
---

## Fusion and the tokamak 

There are many ways of achieving fusion, most promising is magnetically confining the plasma, e.g., with a tokamak. 

:::: {.columns}

::: {.column width="80%"}

![Tokamak overview (EUROfusion)](./figures/tokamak_schematic.jpg){width=90%}
:::

::: {.column width="20%"}
![USSR Stamp 1987 (wikipedia)](./figures/1987_CPA_5891.jpeg)
:::

::::

## The plasma inside is confined, and best parameterized in terms of  flux surface coordinates
:::: {.columns}

::: {.column width="50%"}

![](./figures/img_flux_surf.jpg)
![](./figures/aug_people.jpg)
:::

::: {.column width="50%"}

![](./figures/efit_recons.jpg){height=80%}
:::

::::

## The future is big (literally) but we can't currently extrapolate (missing physics)

![Size scaling of reactors](./figures/bau_size_comparison.jpg){height=40% fig-align="center"}
![](./figures/lcfs_size_comparison.jpeg){height=50% fig-align="center"}

## Overview of tokamak scales 

Inside a magnetic confinement fusion device lives a dynamical system which evolves on many varying spatio-temporal scales. 

:::: {.columns}

::: {.column width="50%"}

**Spatial**

- Molecular level ($<$ nm)
  - Plasma wall interaction 
- gyrorbit radius ($\sim 0.1$ mm)
  - Electron/ion collisions 
- Turbulence (mm-m)
- MHD instabilities (mm-m)
:::

::: {.column width="50%"}

**Temporal**

- GHz 
  - Electron/ion gyrofequencies (20-200)
  - Power injection systems  
- MHz and kHz
  - **Diagnostic capability**
- Hz
  - ELMs and other MHD instabilities 
  - Heat exchange  (collisions)time for ions/electrons
:::

::::

## Motivation 

- Can not reasonably compute Hamiltonian of system ($\sim 1.4 \times 10^{22}$ particles)
- Solving phase space representations e.g., 6-D Vlasov with PIC codes, the resolution needed to run such a simulation at a reactor scale size would likely require more power (computationally) than actually running a device of that size.
  - Grid size: electron/ion gyroradii 
  - Time scale: electron/ion gyrofrequencies

![](./figures/Figure_integrated_modelling.pdf){height=50%}

## Motivation (cont.)
Therefore, we need fast(er), reduced models of the system that are: 

1. Theory driven  
2. **Experiment (data) driven**
3. Theory-emperical hybrid 

## Data driven approach to modeling the plasma state

![](./figures/33194_density.png){fig-align="center" width=60%}

We know our pheonemna we want to model, $\vec{x}$, should be some time evolving function parametermized by at least the machine control parameters, $\vec{c}$, and possibly some stochastic elements we do not have direct control over ($\vec{\kappa}$),  $$\vec{x} = f(\vec{c}, \vec{\kappa}, t) \Rightarrow f(\vec{z}, t)$$ where $z$ are some latent variables that are some unkown combination of controllable parameters and dynamic evolution of internal plasma state.

How to learn $\vec{z}$?. 

## Enter bayes and its variational variations

From a probabilistic point of view, we want to approximate as closely as possible the following distribution: $$p(z | x) = \frac{p(x | z) p(z)}{p(x)}$$

The bottleneck in our case is the evidence, which takes into account **all the values possible** of $x$ for a given $z$: 
$$p(x) = \int p(x|z)p(z)dz$$

## Enter bayes and its variational variations
From a probabilistic point of view, we want to approximate as closely as possible the following distribution: $$p(z | x) = \frac{p(x | z) p(z)}{p(x)}$$

The bottleneck in our case is the evidence, which takes into account all the values possible from $z$: 
$$p(x) = \int p(x|z)p(z)dz$$

From a fusion perspective, in reactor-scale devices, we have very little chance this is in closed form, and if so, the time needed to compute is massive. 

## Enter bayes and its variational variations

Want: posterior $$p(z | x) = \frac{p(x | z) p(z)}{p(x)}$$

Bottleneck: evidence $$p(x) = \int p(x|z)p(z)dz$$

Bayesian people have been clever and proposed many solutions (e.g., MCMC), but for us, with big datasets of observations in a high dimensional space, most previous solutions are computationally infeasable. 

But Kingma and Welling suggest the **Variational Inference framework**, where we will try to approximate the intractable posterior. 

## Variational infrenece

We consider that there is a hidden variable, $z$ that could explain our data, $x$. We want to approximate the intractable posterior density, $p(z |x)$ (how do $z$ vary conditioned on observations). We consider our approximation as a family member of well known densities, and $z$ is what we have to optimize. 


To do so, we introduce the following models: 


:::: {.columns}

::: {.column width="50%"}
**Recognition model (encoder)**
$$q_\phi (z |x)$$
an approximation for true posterior with model parameters $\phi$; i.e., given $x$, what is $z$? 

:::

::: {.column width="50%"}
**Generative model (decoder)**
$$p_\theta (x |z)$$
with model parameters $\theta$, that given $z$ produces a distribution over possible coresponding $x$

:::

::::

Intuitively, if the marginal liklihood, $p(x |z )$, is high, then we have likely chosen a good $z$ to describe $x$. So let's try to maximize the likelihood! 

## Now we have an evidence lower bound over the marginal likelihood

$$\mathcal{L}_\text{ELBO} = -\mathcal{D}_{KL} \left( q_\phi (z | x_i) || p_\theta (z) \right) + \mathbb{E}_{q_\phi (z | x_i)} \left( \log (p_\theta (x_i |z))\right)$$

We want to differentiate and optimize (maximize) $\mathcal{L}$ w.r.t the variational,$\phi$, and generative, $\theta$, parameters. 

$\nabla_{\theta, \phi} \mathcal{L}_\text{ELBO}$ is the gradient w.r.t $\phi$ over the expectation w.r.t $\phi$!.
This in it of itself is not differentiable...

Kingma introduces the noise variable, $\epsilon$, and 'differentiably transforms' $q_\phi (z|x)$ to get a fully diffferentiable set of opearations, which we can use our favourite gradient-based optimization technique to maximize.

## Implementation 
\begin{align*}
\boldsymbol{\mu}_x, \boldsymbol{\sigma}_x &= M(\textbf{x}), \Sigma(\textbf{x}) && \text{Push \textbf{x} through encoder}
\\ \\
\boldsymbol{\epsilon} &\sim \mathcal{N}(0, 1) && \text{Sample noise}
\\ \\
\textbf{z} &= \boldsymbol{\epsilon} \boldsymbol{\sigma}_x + \boldsymbol{\mu}_x  && \text{Reparameterize}
\\ \\
\textbf{x}_r  & = p_{\boldsymbol{\theta}}(\textbf{x} \mid \textbf{z}) && \text{Push \textbf{z} through decoder}
\\ \\
\text{recon. loss} &= \text{MSE}(\textbf{x}, \textbf{x}_r) && \text{Compute reconstruction loss}
\\ \\
\text{var. loss} &= -\text{KL}[\mathcal{N}(\boldsymbol{\mu}_x, \boldsymbol{\sigma}_x) \lVert \mathcal{N}(0, I)] && \text{Compute variational loss}
\\ \\
\text{L} &= \text{recon. loss} + \text{var. loss} && \text{Combine losses}
\end{align*}

## Examples in fusion (1): Dimensionality reduction for disruption prediction 


Idea is to map the high dimensional signals (7) to lower dimension (2) which could be passed to a controler. 

:::: {.columns}

::: {.column width="30%"}
![](./figures/vae_wei_disruption.png){height=100%}
:::

::: {.column width="30%"}
![](./figures/wei_signal.png){height=65%}

:::

::::

## Examples in fusion (1): Dimensionality reduction for disruption prediction 
![](./figures/insitu_control.png){height=50%}
'After training the VAE model, all data were mapped to the latent space by their mean coordinates using the encoder network and then averaged into a two-dimensional grid by calculating the mean andstandard deviation of each of the parameters of the data points within each grid box. The disruptivity score of each sample was assigned bycomparing the time-to-disruption to a 1 ms warning time window'

## Examples in fusion (2) Mapping machine parameters to electron profiles

Here we (i) got fancy and modified the ELBO based on _Ilse, et. al., DIVA ICMLR 2020_. The motivation is that we want to find a mapping of machine control parameters to our $z$. 

![](./figures/DIVA_ARCH.svg.png)


Our latent space is a bit bigger (8D), but we can take slices of the learned $z$ to find regions of $z$ that correspond to useful plasma characteristics and corresponding machine parameters therewith. 

## Examples in fusion (2) Mapping machine parameters to electron profiles: general generative use case

![](./figures/DIVA_output.png)

## Examples in fusion (2) Mapping machine parameters to electron profiles: conditional generative use case


![](./figures/DIVA_CON_GEN.png)

![](./figures/current_sweep.png){height=50%}

## Examples in fusion (3) Learning a time evoliving $z$

The previous examples considered a steady state plasma, but in reality it is dynamic: 

![](./figures/need-for-time-dependence-output-1.png)

## Examples in fusion (3) Learning a time evoliving $z$

![](./figures/forward_model_enc_dec_profs_arch.png)

![](./figures/synopsis_posterior_pulse.png){height=80%}

## Examples in fusion (3) Learning a time evoliving $z$, addition linear constraint to $z$ w.r.t power needed to get to H-mode

![](./figures/lh_predictor.png)

## Future work: Diffusion VAE's 

![](./figures/diffusion_vaes.png){height=60%}

They change the reparameterization mapping to approximate it as a random walk, which they can then project onto an arbitrary Riemannian manifold. 

The benifit is that one can capture topological information of the data, not possible in basic VAE approach. 
