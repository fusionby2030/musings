{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Bayesian Optimization Example for Model Validation\n",
        "format:\n",
        "  html:\n",
        "    code-fold: true\n",
        "    page-layout: full\n",
        "    include-in-body:\n",
        "      - text: '\\usepackage{algorithm2e}'\n",
        "execute:\n",
        "  keep-ipynb: true\n",
        "---"
      ],
      "id": "997fe676"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Given some model $f(x, \\theta)Â \\rightarrow y$, which takes inputs $x$ and free parameters $\\theta$, and maps them to $y \\in \\mathbb{R}^d$.\n",
        "\n",
        "The validation exercise is the following: given an observed measurement or pheonemna $\\hat{y}$, we aim to find $\\theta$ such that $f(x, \\theta) \\sim \\hat{y}$.\n",
        "\n",
        "## Example Model \n",
        "\n",
        "Let's consider the model $$f(x, \\alpha, \\beta) = \\alpha\\sin(x) + \\beta e^{-x}$$\n",
        "\n",
        "The free parameters are $\\alpha, \\beta$. \n"
      ],
      "id": "d91cb6d8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt \n",
        "import numpy as np \n",
        "import matplotlib as mpl \n",
        "\n",
        "model_f = lambda x, alpha, beta: (alpha*np.sin(x) + beta*np.exp(-x)) #  / gamma*np.cos(x)\n",
        "\n",
        "num_samples = 25\n",
        "x_range = np.linspace(-1, 1, num_samples)\n",
        "\n",
        "fig = plt.figure()\n",
        "for i in range(6): \n",
        "  alpha = 4.0 * np.random.randn()\n",
        "  beta = 1.0 * np.random.randn() + 2\n",
        "  gamma = 1 * np.random.randn()\n",
        "  plt.plot(x_range, model_f(x_range, alpha, beta), label=r'$\\alpha$={alpha:.2}; $\\beta$={beta:.2}'.format(alpha=alpha, beta=beta))\n",
        "plt.legend()\n",
        "plt.title(r'Example Model output for various $\\theta$')\n",
        "plt.ylabel(r'$f(x, \\alpha, \\beta)$')\n",
        "plt.xlabel('x')\n",
        "plt.ylim(-10, 10)\n",
        "plt.show()"
      ],
      "id": "d4350f90",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's say we have some noisy measurements now that we want to validate the model against: \n"
      ],
      "id": "c0069729"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "x_range = np.linspace(-1.0, 1.0, num_samples)\n",
        "alpha_target, beta_target = 7.9, 1.4\n",
        "experimental_result = model_f(x_range, alpha_target, beta_target) + 0.4*np.random.randn(x_range.shape[0])\n",
        "target_model = model_f(x_range, alpha_target, beta_target)\n",
        "fig = plt.figure() \n",
        "plt.plot(x_range, target_model, label=r'Target $y$; $\\alpha$={alpha:.2}; $\\beta$={beta:.2}'.format(alpha=alpha_target, beta=beta_target), color='black', alpha=0.3)\n",
        "plt.scatter(x_range, experimental_result, label='Experiment: $\\hat{y}$',)\n",
        "plt.legend()\n",
        "plt.xlabel('x')\n",
        "plt.ylim(-10, 10)\n",
        "plt.show()"
      ],
      "id": "204c65f3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The goal is then to find $\\alpha = 7.9$ and $\\beta = 1.4$. Additionally, it would be nice to know how certain we are about $\\alpha, \\beta$.\n",
        "\n",
        "## Framing validation as an optimization problem\n",
        "\n",
        "\n",
        "Formally, we want to find \n",
        "$$\\underset{{\\theta \\in \\mathcal{D}}}{\\text{argmin}} ( r(f(x, \\theta), \\hat{y}))$$ \n",
        "where $r(f, \\hat{y})$ is a mapping $r: \\mathbb{R}^d\\times\\mathbb{R}^d \\rightarrow \\mathbb{R}^+$ describing the discrepency between the model output and experimental observation, and $\\mathcal{D}$ is the space in which parameters $\\theta$ are constrained. \n",
        "\n",
        "For our example, we can use the L-2 norm as a discrepency function: $$r(f(x, \\theta), \\hat{y}) = | f(x, \\theta) - \\hat{y} | ^2_2$$\n",
        "\n",
        "To visualize the discrepency function, we can sample $\\alpha, \\beta$ and compute $r$. \n"
      ],
      "id": "a3c1f0ea"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from matplotlib import colors as col # .colors import Normalize\n",
        "\n",
        "alphas = np.linspace(-10, 10, 5)\n",
        "betas = np.linspace(-10, 10, 5)\n",
        "\n",
        "disc_func = lambda y, yhat: ((y - yhat)**2).mean(-1) / yhat.shape[0]# np.linalg.norm# lambda y, yhat: (y - yhat)**2\n",
        "\n",
        "grid = np.dstack(np.meshgrid(alphas, betas)).reshape(-1, 2)\n",
        "\n",
        "discs = np.empty(grid.shape[0])\n",
        "for i, pair in enumerate(grid): \n",
        "  model_out = model_f(x_range, *pair)\n",
        "  discrepency = disc_func(model_out, experimental_result)\n",
        "  discs[i] = discrepency\n",
        "\n",
        "cm = plt.get_cmap('plasma')\n",
        "scmap = plt.cm.ScalarMappable(col.Normalize(vmin=0.0, vmax=max(discs)), cm)\n",
        "colors = scmap.to_rgba(discs)\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
        "for c, pair in zip(colors, grid): \n",
        "  axs[0].plot(x_range, model_f(x_range, *pair), c=c)\n",
        "axs[0].scatter(x_range, experimental_result, label='Experiment: $\\hat{y}$', color='black')\n",
        "axs[1].scatter(grid[:, 0], grid[:, 1], c=discs, vmin=0, vmax=max(discs), cmap=cm)\n",
        "axs[1].scatter(alpha_target, beta_target, marker='*', s=50, color=scmap.to_rgba(disc_func(target_model, experimental_result)))\n",
        "axs[1].set_xlabel(r'$\\alpha$')\n",
        "axs[1].set_ylabel(r'$\\beta$')\n",
        "axs[0].set_title('Model outputs')\n",
        "axs[1].set_title(r'Discrepency Function against various $\\theta$')\n",
        "fig.colorbar(scmap, ax = axs[1], label='r')\n",
        "plt.show()"
      ],
      "id": "10519e65",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In real world examples, we do not have direct (analytical) access to $r$. Therefore, we want to make an approximate of $r$. \n",
        "\n",
        "## Surrogate model of $r$\n",
        "\n",
        "$r$ can be approximated by any number of functions. Therefore, a Gaussian Process Regression (GPR) is a good start. A good overview of GPRs can be found in _Rasmussen and Williams, GPML 2006_. The points relevant to this discusison are that: i) GPR defines a family (distribution) of functions, normally Guassian, and ii) like any model, a GPR has hyperparameters, typically $D + 3$ parameters, for $D$ dimensionality of the data you want to fit (in this case 2). The traditional GPR thus learns a model that outputs a distribution: \n",
        "$$\\hat{r} \\sim \\mathcal{N}(\\mu (\\theta), \\sigma (\\theta))$$\n",
        "\n",
        "where $\\mu$ and $\\sigma$ are deterimed by what are called the kernel and mean function of the GPR. The kernel and mean function have hyperparameters that we must find. Another key point is that the kernel and mean function are differentiable functions. \n",
        "\n",
        "We are only as good as our surrogate model. To find a good surrogate model, we must find the proper hyperparameters of the kernel and mean function of the GPR. \n",
        "\n",
        "###  Approach 1: Point-wise estimation via maximizng the log-likelihood \n",
        "\n",
        "In this example, we will use a Gaussian likelihood GPR, i.e., we say that the probability density of observing a point $R = r(\\theta)$ that is generated by a Gaussian distribution is given by: \n",
        "\n",
        "$$P(R, \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp \\left( -\\frac{(R - \\mu)^2}{2\\sigma^2}\\right)$$\n",
        "where, one again, $\\mu$ and $\\sigma$ are outputs of our GPR. Notice this probability distribution has a maximum if the mean output of our GPR matches that of the point we observe, i.e., $\\mu = R$. If we have mutliple points to fit, $\\vec{R} = (r(\\theta_1), r(\\theta_2), r(\\theta_3), \\dots, R_i)$, then the total joint probability distribution of observing all the points is given by the product of their likelihood: \n",
        "\n",
        "$$P(\\vec{R}, \\mu, \\sigma) = \\prod_i \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp \\left( -\\frac{(R_i - \\mu)^2}{2\\sigma^2}\\right)$$\n",
        "\n",
        "However, it is easy to see that with many points, we will likely hit some numerical underflow, therefore we can make use of the logarithm:, \n",
        "$$\\ln(P(\\vec{R}, \\mu, \\sigma)) = i\\ln \\left(\\frac{1}{\\sigma \\sqrt{2\\pi}}\\right) - \\sum_i \\left(\\frac{(R_i - \\mu)^2}{2\\sigma^2}\\right)$$\n",
        "\n",
        "We can then differentiate this function in order to find the maximum and apply our favourite gradient based optimizer to find the hyperparameters of the kernel and mean function that determine $\\mu$ and $\\sigma$. This approach is called Maximum Likelihood Estimation (MLE). **Note**: This is called point-wise because we are estimating the hyperparameters of the GP 'per point' we use to fit the GP. \n",
        "\n",
        "Below is an example of the  'lengthscale' parameters of the covariance function, where the countours are the(negative) log-likelihood estimation. \n"
      ],
      "id": "19473f50"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import gpytorch \n",
        "import torch \n",
        "import botorch \n",
        "\n",
        "model_f_torch = lambda x, alpha, beta: (alpha*torch.sin(x) + beta*torch.exp(-x)) \n",
        "experimental_result_torch = torch.from_numpy(experimental_result)\n",
        "disc_fun_torch = torch.nn.MSELoss(reduction='none')\n",
        "\n",
        "train_x = torch.from_numpy(grid).reshape(-1, 2)\n",
        "x_range_train = torch.tile(torch.from_numpy(x_range), (train_x.shape[0], 1))\n",
        "model_output = model_f_torch(x_range_train, train_x[:, 0].unsqueeze(-1), train_x[:, 1].unsqueeze(-1))\n",
        "train_y = disc_fun_torch(experimental_result_torch.repeat((model_output.shape[0], 1)), model_output).mean(-1) / x_range_train.shape[-1]\n",
        "\n",
        "\n",
        "# We will use the simplest form of GP model, exact inference\n",
        "class ExactGPModel(gpytorch.models.ExactGP, botorch.models.gpytorch.GPyTorchModel):\n",
        "    num_outputs = 1\n",
        "    def __init__(self, train_x, train_y, likelihood):\n",
        "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
        "        self.mean_module = gpytorch.means.ConstantMean(constant_prior=gpytorch.priors.NormalPrior(0, 1))\n",
        "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=train_x.shape[-1]))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        mean_x = self.mean_module(x)\n",
        "        covar_x = self.covar_module(x)\n",
        "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
        "\n",
        "# initialize likelihood and model\n",
        "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
        "model = ExactGPModel(train_x, train_y, likelihood)\n",
        "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)"
      ],
      "id": "7a347f98",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-cap: \"An MLE optimization run using the Adam optimizer for GPR kernel lenghtscales (outputscales, mean function scale, and likelihood noise are fixed). Even for a uni-model landscape, if the mode is very flat, it can result in many optimizers getting stuck. This is why multiple restart optimizers are useful for global hyperparameter finding.\"\n",
        "\n",
        "model.likelihood.noise = torch.tensor(0.1)\n",
        "model.mean_module.constant = torch.tensor(5.750)\n",
        "model.covar_module.outputscale = torch.tensor(5.786)\n",
        "\n",
        "model.covar_module.base_kernel.lengthscale = torch.tensor([5.3, 3.535])\n",
        "\n",
        "\n",
        "lscale_1_range = torch.linspace(0.1, 20, 100)\n",
        "lscale_2_range = torch.linspace(0.1, 10, 100)\n",
        "image = np.empty((100, 100))\n",
        "for i, lscale_1 in enumerate(lscale_1_range): \n",
        "  for j, lscale_2 in enumerate(lscale_2_range): \n",
        "    model.covar_module.base_kernel.lengthscale = torch.tensor([lscale_1,lscale_2])\n",
        "    # model.likelihood.noise = torch.tensor(noiscale.item())\n",
        "    output = model(train_x)\n",
        "    loss = -mll(output, train_y)\n",
        "    image[i, j] = loss\n",
        "\n",
        "fig = plt.figure() \n",
        "cax = plt.contour(lscale_1_range, lscale_2_range, image, 50)\n",
        "plt.yscale('log')\n",
        "plt.xscale('log')\n",
        "plt.xlabel(r'Length scale $\\alpha$')\n",
        "plt.ylabel(r'Length scale $\\beta$')\n",
        "# extent = (1.0, 20.0, 1.0, 20.0)\n",
        "#cax = plt.imshow(image, extent=extent)\n",
        "fig.colorbar(cax, label='- log-likelihood')\n",
        "\n",
        "\n",
        "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
        "model = ExactGPModel(train_x, train_y, likelihood)\n",
        "# mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
        "\n",
        "training_iter = 200\n",
        "# Find optimal model hyperparameters\n",
        "model.train()\n",
        "likelihood.train()\n",
        "\n",
        "\n",
        "model.likelihood.noise = torch.tensor(0.1)\n",
        "model.mean_module.constant = torch.tensor(5.750)\n",
        "model.covar_module.outputscale = torch.tensor(5.786)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.05)  # Includes GaussianLikelihood parameters\n",
        "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
        "lscale_1_mle, lscale_2_mle = [], []\n",
        "for i in range(training_iter):\n",
        "    optimizer.zero_grad()\n",
        "    output = model(train_x)\n",
        "    loss = -mll(output, train_y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    lscale_1_mle.append(model.covar_module.base_kernel.lengthscale.squeeze()[0].detach().numpy())\n",
        "    lscale_2_mle.append(model.covar_module.base_kernel.lengthscale.squeeze()[1].detach().numpy())\n",
        "\n",
        "plt.plot(lscale_1_mle,lscale_2_mle, color='black', label='Opt. route')\n",
        "plt.scatter(lscale_1_mle[0],lscale_2_mle[0], color='red', marker='*', s=200, label='Starting point')\n",
        "plt.scatter(lscale_1_mle[-1],lscale_2_mle[-1], color='salmon', marker='*', s=200, label=f'{training_iter} optimization steps', zorder=30)\n",
        "\n",
        "model.covar_module.base_kernel.lengthscale = torch.tensor([1., 1.], requires_grad=True)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.05)  # Includes GaussianLikelihood parameters\n",
        "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
        "lscale_1_mle, lscale_2_mle = [], []\n",
        "for i in range(training_iter):\n",
        "    optimizer.zero_grad()\n",
        "    output = model(train_x)\n",
        "    loss = -mll(output, train_y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    lscale_1_mle.append(model.covar_module.base_kernel.lengthscale.squeeze()[0].detach().numpy())\n",
        "    lscale_2_mle.append(model.covar_module.base_kernel.lengthscale.squeeze()[1].detach().numpy())\n",
        "\n",
        "\n",
        "plt.plot(lscale_1_mle,lscale_2_mle, color='black')\n",
        "plt.scatter(lscale_1_mle[0],lscale_2_mle[0], color='red', marker='*', s=200)\n",
        "plt.scatter(lscale_1_mle[-1],lscale_2_mle[-1], color='salmon', marker='*', s=200, zorder=30)\n",
        "\n",
        "plt.legend(loc='lower left')\n",
        "plt.show()"
      ],
      "id": "ef2490c3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Remember, we will use the surrogate model as a proxy for finding the optimal model inputs, therefore, if we just blindly trust the MLE of hyperparameters selection, we may be wrong! In the case that we are wrong, we don't have much in terms of quantifying how uncertain we are about the wrong fit just fitting the MLE. \n",
        "\n",
        "Regardless, for small dimensionality and sufficiently uni-modal landscape, MLE gives a decent approximation. \n"
      ],
      "id": "a59b9f3d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-cap: \"MLE for all hyperparameters of GPR results in decent approximation.\"\n",
        "def plot_evaluation(model, likelihood, acq_suggest = None): \n",
        "  # Set into eval mode\n",
        "  model.eval()\n",
        "  likelihood.eval()\n",
        "\n",
        "  # Test points\n",
        "  n1, n2 = 75, 75\n",
        "  alphas, betas = np.linspace(-10, 10, n1), np.linspace(-10, 10, n2)\n",
        "\n",
        "  # Make predictions\n",
        "  with torch.no_grad(), gpytorch.settings.fast_computations(log_prob=False, covar_root_decomposition=False):\n",
        "      test_x = torch.from_numpy(np.dstack(np.meshgrid(alphas, betas)).reshape(-1, 2))\n",
        "      predictions = likelihood(model(test_x))\n",
        "      mean = predictions.mean\n",
        "      x_range_test = torch.tile(torch.from_numpy(x_range), (test_x.shape[0], 1))\n",
        "      model_output = model_f_torch(x_range_test, test_x[:, 0].unsqueeze(-1), test_x[:, 1].unsqueeze(-1))\n",
        "      discrepency_output = disc_fun_torch(experimental_result_torch.repeat((model_output.shape[0], 1)), model_output).mean(-1) / x_range_test.shape[-1]\n",
        "\n",
        "  fig, ax = plt.subplots(1, 2, figsize=(10, 10))\n",
        "  extent = (alphas.min(), alphas.max(), betas.min(), betas.max())\n",
        "  ax[1].imshow(np.flip(mean.detach().numpy().reshape(n1, n2), 0), extent=extent, cmap=plt.get_cmap('plasma'))\n",
        "  \n",
        "  \n",
        "  ax[0].set_title('True Discrepency')\n",
        "  ax[0].imshow(np.flip(discrepency_output.detach().numpy().reshape(n1, n2), 0), extent=extent, cmap=plt.get_cmap('plasma'))\n",
        "  ax[1].set_title('GPR values')\n",
        "  for a in ax: \n",
        "    a.scatter(train_x[:, 0], train_x[:, 1], color='grey')\n",
        "    a.set_xlabel(r'$\\alpha$')\n",
        "    a.set_ylabel(r'$\\beta$')\n",
        "    a.scatter(alpha_target, beta_target, marker='*', color='green', s=400)\n",
        "  if acq_suggest is not None: \n",
        "    ax[1].scatter(*acq_suggest[0], color='red', label='Acquisition Suggestion', s=400, marker='*')\n",
        "  else: \n",
        "    ax[1].scatter(*test_x[torch.argmin(mean)], color='red', label='Current optimum')\n",
        "  plt.show()\n",
        "\n",
        "likelihood_mle = gpytorch.likelihoods.GaussianLikelihood()\n",
        "model_mle = ExactGPModel(train_x, train_y, likelihood)\n",
        "# mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
        "\n",
        "training_iter = 300\n",
        "model_mle.train()\n",
        "likelihood_mle.train()\n",
        "\n",
        "optimizer = torch.optim.Adam(model_mle.parameters(), lr=0.05)  # Includes GaussianLikelihood parameters\n",
        "\n",
        "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood_mle, model_mle)\n",
        "\n",
        "for i in range(training_iter):\n",
        "    optimizer.zero_grad()\n",
        "    output = model_mle(train_x)\n",
        "    loss = -mll(output, train_y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "print(\"Iter %d/%d - Loss: %.3f   lengthscales: %.3f, %.3f   noise: %.3f  mean length: %.3f  outputscale: %.3f\" % (i + 1, training_iter, loss.item(),\n",
        "    model_mle.covar_module.base_kernel.lengthscale.squeeze()[0],\n",
        "    model_mle.covar_module.base_kernel.lengthscale.squeeze()[1],\n",
        "    model_mle.likelihood.noise.item(), \n",
        "    model_mle.mean_module.constant, \n",
        "    model_mle.covar_module.outputscale,\n",
        "))\n",
        "\n",
        "plot_evaluation(model_mle, likelihood_mle)"
      ],
      "id": "a4ee73c1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generally, the fit is alright. It's nice how we already have a close approximation of what should be the optimal value! \n",
        "\n",
        "### Approach 2: Marginalizing the hyperparameters out\n",
        "\n",
        "According to Bayesian formalisim [^1], we should start with a prior distribution over the hyperparameters, $P(\\text{hyper})$, which is in turn modified using training data $\\theta$ to produce a posterior $P(\\text{hyper}|\\theta)$. To make predictions, we should then integrate over the posterior. With the above example, the predicted mean output of the GPR is $\\hat{\\mu}(\\theta_i)$ for a given input $\\theta_i$ is: \n",
        "\n",
        "$$\\hat{\\mu} (\\theta_i) = \\int \\mu_{\\text{hyper}} (\\theta_i) P(\\text{hyper}|\\theta) d\\text{hyper}$$ \n",
        "where $\\mu_{\\text{hyper}}$ is the preidcted mean for a particular value of $\\text{hyper}$. \n",
        "\n",
        "In this simple case, this is actually analytically feasable, but with fusion models, typically not. Therefore, we can apply MCMC and its friends. So we perscribe priors distributions over $P(\\text{hyper})$ and use MCMC to give us samples from the posterior. \n",
        "\n",
        "[^1]: This formulation is more or less copied directly from _Gaussian Processes for Regression_ from Williams and Rasmussen. \n",
        "\n",
        "More details on this method are found at the bottom of the page, but for now I just show the results of MCMC integration with NUTS.  \n",
        "\n",
        "![Example MCMC Chains from integratin](./figures/MCMC_CHAINS_EXAMPLE.png)\n",
        "\n",
        "We can then take draws from the above posterior distributions. \n"
      ],
      "id": "ed5acdb6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "pyro_dict = torch.load('./pyro_mcmc_out.pth')\n",
        "state_dict = torch.load('./example_model.pth')\n",
        "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
        "model = ExactGPModel(train_x, train_y, likelihood)\n",
        "model.load_strict_shapes(False) \n",
        "model.load_state_dict(state_dict)\n",
        "model.pyro_load_from_samples(pyro_dict)\n",
        "\n",
        "\n",
        "for key, val in model.named_parameters(): \n",
        "    if key in ['mean_module.raw_constant']: \n",
        "        num_draws = val.shape[0]\n",
        "        \n",
        "model.eval()\n",
        "likelihood.eval()\n",
        "\n",
        "n1, n2 = 75, 75\n",
        "alphas, betas = np.linspace(-10, 10, n1), np.linspace(-10, 10, n2)\n",
        "\n",
        "# Make predictions\n",
        "with torch.no_grad(), gpytorch.settings.fast_computations(log_prob=False, covar_root_decomposition=False):\n",
        "    test_x = torch.from_numpy(np.dstack(np.meshgrid(alphas, betas)).reshape(-1, 2))\n",
        "    expanded_test_x = test_x.unsqueeze(0).repeat(num_draws, 1, 1)\n",
        "    \n",
        "    predictions = likelihood(model(expanded_test_x))\n",
        "    mean_out_samples = predictions.mean\n",
        "    x_range_test = torch.tile(torch.from_numpy(x_range), (test_x.shape[0], 1))\n",
        "    model_output = model_f_torch(x_range_test, test_x[:, 0].unsqueeze(-1), test_x[:, 1].unsqueeze(-1))\n",
        "    discrepency_output = disc_fun_torch(experimental_result_torch.repeat((model_output.shape[0], 1)), model_output).mean(-1) / x_range_test.shape[-1]\n",
        "\n",
        "fig, axs = plt.subplots(3, 2, figsize=(8, 15))\n",
        "ax = axs.ravel()\n",
        "extent = (alphas.min(), alphas.max(), betas.min(), betas.max())\n",
        "\n",
        "ax[0].set_title('True Discrepency')\n",
        "ax[0].imshow(np.flip(discrepency_output.detach().numpy().reshape(n1, n2), 0), extent=extent, cmap=plt.get_cmap('plasma'))\n",
        "ax[1].set_title('GPR Mean Realization')\n",
        "ax[1].imshow(np.flip(mean_out_samples.mode(0)[0].detach().numpy().reshape(n1, n2), 0), extent=extent, cmap=plt.get_cmap('plasma'))\n",
        "ax[1].scatter(*test_x[torch.argmin(mean_out_samples.mode(0)[0])], color='red', label='Current optimum')\n",
        "\n",
        "to_plot = 114\n",
        "for k, to_plot in enumerate([100, 8, -1, 650]):\n",
        "    ax[2+k].imshow(np.flip(mean_out_samples[to_plot].detach().numpy().reshape(n1, n2), 0), extent=extent, cmap=plt.get_cmap('plasma'))\n",
        "    ax[2+k].scatter(*test_x[torch.argmin(mean_out_samples[to_plot])], color='red', label='Current optimum')\n",
        "    ax[2+k].set_title(f'GPR Sample {to_plot} Realization')\n",
        "    \n",
        "for a in ax: \n",
        "    a.set_xlabel(r'$\\alpha$')\n",
        "    a.set_ylabel(r'$\\beta$')\n",
        "    a.scatter(alpha_target, beta_target, marker='*', color='green', s=400)\n",
        "plt.show()"
      ],
      "id": "0dd55945",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Example draws from posterior realization](./figures/MCMC_POSTERIOR_REALIZATION.png)\n",
        "\n",
        "Now that we have a fitted surrogate model, we would like a way to query it to obtain new points ($\\alpha, \\beta$), that hopefully better fit the experimental data with our model.\n",
        "\n",
        "## Aquiring new points from the surrogate model\n",
        "\n",
        "This is done using an _aquisition function_: \n",
        "$$ \\alpha (\\theta | \\text{hyper}): \\mathcal{R}^d \\rightarrowtail \\mathcal{R}$$\n",
        "\n",
        "They essentially measure the quality of a point $\\theta$ (here once again our $\\alpha, \\beta$), and decide at which location of $\\theta \\in \\mathcal{D}$ is most 'promising'. The acquisition function is based on our surrogte models predictive distribution $p(R | \\theta, \\text{hyper})$. Usually, the acquistion function depends on the posterior mean prediction, $\\mu(\\theta)$, and the associated posterior uncertainty, $\\sigma(\\theta)$. \n",
        "\n",
        "A popular acquisition function is the Expected improvement [Source]: \n",
        "$$\\alpha_{\\text{EI}} (\\theta | \\text{hyper}) = \\mathcal{E}_{p(R | \\theta, \\text{hyper})} \\left[ \\text{min}(R^* - R(\\theta), 0 )\\right]$$ \n",
        "\n",
        "where $R^*$ is the best function value observed so far, i.e., minimum discrepency. This measures the expected negative improvement (since we are minimizing) over the best function value observed so far. \n",
        "\n",
        "The way we use the acquisition function will change depending on if we took approach 1 or 2 from above. \n",
        "\n",
        "### Approach 1: Using the MLE surrogate \n",
        "\n",
        "From our surrogate model with $\\text{hyper}$ determined by MLE, we can plug in $\\mu$, $\\sigma$ into the above equation.  \n"
      ],
      "id": "1e13a875"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_mle.eval() \n",
        "likelihood_mle.eval()\n",
        "\n",
        "import botorch \n",
        "\n",
        "\n",
        "acq_fun = botorch.acquisition.analytic.ExpectedImprovement(model_mle, best_f = train_y.min(), maximize=False)\n",
        "\n",
        "bounds = torch.stack([torch.ones(2)*-10, torch.ones(2)*10.0])\n",
        "candidate, acq_val = botorch.optim.optimize_acqf(acq_fun, bounds=bounds, q=1, num_restarts=5, raw_samples=20)\n",
        "plot_evaluation(model_mle, likelihood_mle, candidate)"
      ],
      "id": "4f3ee397",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see already that the MLE optimized model gives a very good first guess on where to sample from next! \n",
        "\n",
        "### Approach 2: Using the integrated predictive posterior\n",
        "\n",
        "Since we have marginalized out the hyperparameters, our aquisition function becomes: \n",
        "\n",
        "$$\\text{acq}(x | R, X) = \\int \\text{acq}(x|\\text{hyper}) P(\\text{hyper}|R) d\\text{hyper}$$\n",
        "\n",
        "but since we have performed MCMC integration, this is discretized: \n",
        "\n",
        "$$\\text{acq}(x | R) \\approx \\frac{1}{M} \\sum_{m=1}^M \\text{acq}(x | \\text{hyper}^m )$$ \n",
        "\n",
        "where ${\\text{hyper}^1, \\dots, \\text{hyper}^m}$ are samples drawn from  $p(\\text{hyper}|R)$. In essence, we draw models via the hyperparameter posterior, $\\theta$, which yield us $\\mu$, $\\sigma$ for each model, and apply the acquisition function to each, averaging over all outputs as our desired point. \n",
        "\n",
        "\n",
        "![Example acquisition function by averaging over GP integration realizations](./figures/ACQ_OVER_MCMC_INT.png)\n",
        "\n",
        "## Putting it all together\n",
        "\n",
        "The full BO algorithm looks like the following: \n",
        "![Bo Algorithm](./figures/bo_algorithm.png)\n",
        "\n",
        "Lets show the evolution in practice. \n",
        "\n",
        "\n",
        "\n",
        "# Further notes \n",
        "\n",
        "#### MCMC practice \n",
        "\n",
        "To do this in practice, we need to know more about the underlying GPR model, and how it learns from the data. \n",
        "\n",
        "##### GPR as combination of kernel and mean function \n",
        "\n",
        "##### Mean Function \n",
        "\n",
        "##### Kernel\n",
        "\n",
        "$$k_\\text{RBF}(x_i, x_j) = \\sigma_f^2 \\exp\\left(-\\sum_{i=1}^{d}\\frac{\\left(x_{i,k} - x_{j,k}\\right)^2}{2l_k^2}\\right)$$\n",
        "where $l_k$ and $\\sigma$ are the hyperparameters parameters of the kernel function. \n",
        "\n",
        "#### Together\n",
        "\n",
        "We use the **pymc3** library to do the MCMC sampling [^2]. \n",
        "\n",
        "[^2]: The [gpytorch example](https://docs.gpytorch.ai/en/stable/examples/01_Exact_GPs/GP_Regression_Fully_Bayesian.html) uses pyro, but I found this to be a nightmare and didn't work. \n"
      ],
      "id": "565b99ba"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: true\n",
        "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
        "model = ExactGPModel(train_x, train_y, likelihood)\n",
        "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
        "\n",
        "X = mll.model.train_inputs[0].numpy() \n",
        "y = mll.model.train_targets.numpy()\n",
        "d = X.shape[1] \n",
        "\n",
        "gp_noise_prior = None \n",
        "noise_size = mll.likelihood.noise_covar.noise[0].item()\n",
        "\n",
        "n_lengthscales = mll.model.covar_module.base_kernel.raw_lengthscale.numel()\n",
        "ard_dim = n_lengthscales if n_lengthscales > 1 else 1\n",
        "\n",
        "import arviz as az\n",
        "import pymc3 as pm \n",
        "with pm.Model() as model: \n",
        "  ls_mu = 20.0/3.0\n",
        "  os_mu = 1.0 \n",
        "  ls_prior = pm.HalfNormal('lengthscale', ls_mu, shape=ard_dim)\n",
        "  os_prior = pm.HalfNormal('outputscale', 3.0)\n",
        "  mean_prior = pm.HalfNormal('constant', 2.0)\n",
        "  noise_prior = pm.LogNormal('noise', 1.0)\n",
        "\n",
        "  cov = pm.gp.cov.Exponential(d, ls=ls_prior)\n",
        "  cov *= pm.gp.cov.Constant(os_prior)\n",
        "  mean_func = pm.gp.mean.Constant(mean_prior)\n",
        "  gp = pm.gp.Marginal(cov_func=cov, mean_func=mean_func)\n",
        "\n",
        "  _ = gp.marginal_likelihood(\"y\", X=X, y=y, noise=noise_prior)\n",
        "with model: \n",
        "   trace = pm.sample(draws = 4000, tune=100, chains=8, compute_convergence_checks=True, target_accept=0.95, return_inferencedata=False, n_init=1000)\n",
        "   prior = pm.sample_prior_predictive()\n",
        "   posterior_predictive = pm.sample_posterior_predictive(trace)\n",
        "   data = az.from_pymc3(trace=trace, prior=prior, posterior_predictive=posterior_predictive)"
      ],
      "id": "d2b26e63",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
        "model = ExactGPModel(train_x, train_y, likelihood)\n",
        "# mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
        "\n",
        "training_iter = 100\n",
        "# Find optimal model hyperparameters\n",
        "model.train()\n",
        "likelihood.train()\n",
        "\n",
        "# Use the adam optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.05)  # Includes GaussianLikelihood parameters\n",
        "\n",
        "# \"Loss\" for GPs - the marginal log likelihood\n",
        "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
        "\n",
        "for i in range(training_iter):\n",
        "    optimizer.zero_grad()\n",
        "    output = model(train_x)\n",
        "    loss = -mll(output, train_y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "print(\"Iter %d/%d - Loss: %.3f   lengthscales: %.3f, %.3f   noise: %.3f  mean length: %.3f  outputscale: %.3f\" % (i + 1, training_iter, loss.item(),\n",
        "    model.covar_module.base_kernel.lengthscale.squeeze()[0],\n",
        "    model.covar_module.base_kernel.lengthscale.squeeze()[1],\n",
        "    model.likelihood.noise.item(), \n",
        "    model.mean_module.constant, \n",
        "    model.covar_module.outputscale,\n",
        "))\n",
        "\n",
        "plot_evaluation(model, likelihood)"
      ],
      "id": "82389753",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have a surrogate of $r$, we would like to now start trying to minimize it efficiently, i.e., we need an approach to start _aquiring_ new points $\\alpha, \\beta$, with the goal of finding $\\underset{{\\alpha, \\beta}}{\\text{argmin}} ( r(\\alpha, \\beta))$ with the least amount of new points possible. \n",
        "\n",
        "## Acquisition function \n",
        "\n",
        "TBD not finished yet. \n",
        "\n",
        "### BACKUP: notes on GPRs\n",
        "\n",
        "\n",
        "GPR defines a family of functions \n",
        "$$ f(\\boldsymbol{x}) \\sim \\mathcal{GP}(m(\\boldsymbol{x}), k(\\boldsymbol{x},\\boldsymbol{x'}))$$\n",
        "\n",
        "where $m(\\boldsymbol {x}) = \\mathbb {E}[f(\\boldsymbol {x})]$ is a mean function, a $k(\\boldsymbol {x},\\boldsymbol {x'}) = \\mathbb {E}[(f(\\boldsymbol {x}) - m(\\boldsymbol {x}))(f(\\boldsymbol {x'}) - m(\\boldsymbol {x}'))]$ is a covariance function, or kernel. \n",
        "\n",
        "\n",
        "The mean function suggests how the expectation of the output,$f$, will change as $\\boldsymbol {x}$ changes. If the mean function is $0$, then as we change $\\boldsymbol {x}$,  variance of the mean of $f$ will also not change. \n",
        "\n",
        "The kernel describes the point-to-point variance of $f$, in other words, the smoothness assumption on the possible functions of $f$. A common kernel function is the RBF: \n",
        "$$k_\\text{RBF}(x_i, x_j) = \\sigma_f^2 \\exp\\left(-\\sum_{i=1}^{d}\\frac{\\left(x_{i,k} - x_{j,k}\\right)^2}{2l_k^2}\\right)$$\n",
        "where $l$ and $\\sigma$ are the free parameters of the kernel model. **These parameters need to be fit.**\n",
        "\n",
        "An example is given below of a GPR with RBF kernel and Constant Mean, fit on the grid of points given before. I modify the output and length scale to show how the function changes. Then, I plot mean output of the GPR, i.e., the Expectation over the family of functions output.  \n"
      ],
      "id": "54ea90ad"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
        "model = ExactGPModel(train_x, train_y, likelihood)\n",
        "# mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
        "\n",
        "training_iter = 100\n",
        "# Find optimal model hyperparameters\n",
        "model.train()\n",
        "likelihood.train()\n",
        "\n",
        "# Use the adam optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.05)  # Includes GaussianLikelihood parameters\n",
        "\n",
        "# \"Loss\" for GPs - the marginal log likelihood\n",
        "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
        "\n",
        "for i in range(training_iter):\n",
        "    optimizer.zero_grad()\n",
        "    output = model(train_x)\n",
        "    loss = -mll(output, train_y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "print(\"Iter %d/%d - Loss: %.3f   lengthscales: %.3f, %.3f   noise: %.3f  mean length: %.3f  outputscale: %.3f\" % (i + 1, training_iter, loss.item(),\n",
        "    model.covar_module.base_kernel.lengthscale.squeeze()[0],\n",
        "    model.covar_module.base_kernel.lengthscale.squeeze()[1],\n",
        "    model.likelihood.noise.item(), \n",
        "    model.mean_module.constant, \n",
        "    model.covar_module.outputscale,\n",
        "))\n",
        "\n",
        "plot_evaluation(model, likelihood)"
      ],
      "id": "09c8588d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# Set into eval mode\n",
        "model.eval()\n",
        "likelihood.eval()\n",
        "\n",
        "# Initialize plots\n",
        "\n",
        "# Test points\n",
        "n1, n2 = 75, 75\n",
        "alphas, betas = np.linspace(-10, 10, n1), np.linspace(-10, 10, n2)\n",
        "\n",
        "# Make predictions\n",
        "with torch.no_grad(), gpytorch.settings.fast_computations(log_prob=False, covar_root_decomposition=False):\n",
        "    # test_x = torch.stack([xv.reshape(n1*n2, 1), yv.reshape(n1*n2, 1)], -1).squeeze(1)\n",
        "    test_x = torch.from_numpy(np.dstack(np.meshgrid(alphas, betas)).reshape(-1, 2))\n",
        "    predictions = likelihood(model(test_x))\n",
        "    mean = predictions.mean\n",
        "    x_range_test = torch.tile(torch.from_numpy(x_range), (test_x.shape[0], 1))\n",
        "    model_output = model_f_torch(x_range_test, test_x[:, 0].unsqueeze(-1), test_x[:, 1].unsqueeze(-1))\n",
        "    discrepency_output = disc_fun_torch(experimental_result_torch.repeat((model_output.shape[0], 1)), model_output).mean(-1) / x_range_test.shape[-1]\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(10, 10))\n",
        "# ax[1].scatter(test_x[:, 0], test_x[:, 1], c=mean.detach().numpy(), vmin=0, vmax=max(mean), cmap=cm)\n",
        "# print(test_x[torch.argmin(discrepency_output)], min(discrepency_output), test_x[torch.argmin(mean)])\n",
        "extent = (alphas.min(), alphas.max(), betas.min(), betas.max())\n",
        "ax[1].imshow(np.flip(mean.detach().numpy().reshape(n1, n2), 0), extent=extent, cmap=plt.get_cmap('plasma'))\n",
        "ax[0].scatter(*test_x[torch.argmin(discrepency_output)], color='black')\n",
        "ax[1].scatter(*test_x[torch.argmin(mean)], color='red', label='Current optimum')\n",
        "ax[0].set_title('True Discrepency')\n",
        "ax[0].imshow(np.flip(discrepency_output.detach().numpy().reshape(n1, n2), 0), extent=extent, cmap=plt.get_cmap('plasma'))\n",
        "axs[1].scatter(train_x[:, 0], train_x[:, 1], color='grey', s=40)\n",
        "# cax = ax[1].imshow(mean.detach().numpy().reshape(n1, n2), extent=extent, cmap=plt.get_cmap('plasma'))\n",
        "ax[1].set_title('GPR values')\n",
        "# fig.colorbar(cax, ax=ax[1])\n",
        "plt.show()"
      ],
      "id": "6f609757",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Relevant papers\n",
        "\n",
        "- https://arxiv.org/pdf/1206.2944.pdf\n",
        "- https://proceedings.neurips.cc/paper_files/paper/1995/file/7cce53cf90577442771720a370c3c723-Paper.pdf\n",
        "- https://doi.org/10.1016/j.nucengdes.2018.06.004\n",
        "- https://doi.org/10.1017/S0022377822001210\n",
        "- https://arxiv.org/pdf/2105.00894v1.pdf\n",
        "  - [code](https://github.com/georgedeath/how-bayesian-should-BO-be/blob/master/fbbo/gp.py)\n",
        "- [Rasmussen](http://gaussianprocess.org/gpml/chapters/RW5.pdf)\n",
        "- [Marganlizing with sequential MC](https://arxiv.org/pdf/1502.01908.pdf)\n",
        "- https://proceedings.neurips.cc/paper/2012/file/05311655a15b75fab86956663e1819cd-Paper.pdf\n",
        "  - Arxiv: https://arxiv.org/pdf/1206.2944.pdf\n",
        "##### Relevant code links \n",
        "\n",
        "- [Hyperparameters in gpytorch](https://docs.gpytorch.ai/en/stable/examples/00_Basic_Usage/Hyperparameters.html)\n",
        "- [Fully bayesian sampling](https://docs.gpytorch.ai/en/stable/examples/01_Exact_GPs/GP_Regression_Fully_Bayesian.html)\n",
        "- [Robust Fully Bayesian](https://betanalpha.github.io/assets/case_studies/gp_part3/part3.html#4_adding_an_informative_prior_for_the_length_scale)"
      ],
      "id": "3f14626f"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}